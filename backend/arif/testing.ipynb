{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "gold_data = yf.download('GLD', start='2015-04-04', end='2024-04-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data = gold_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data['MA_10'] = gold_data['Close'].rolling(window=10).mean()\n",
    "gold_data['MA_50'] = gold_data['Close'].rolling(window=50).mean()\n",
    "gold_data['Volatility'] = gold_data['Close'].rolling(window=10).std()\n",
    "gold_data['Return'] = gold_data['Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define features and target\n",
    "features = ['MA_10', 'MA_50', 'Volatility', 'Return']\n",
    "X = gold_data[features]\n",
    "y = gold_data['Close']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a regression model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data2 = yf.download('GLD', start='2024-03-02', end='2024-05-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data2 = gold_data2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data2['MA_10'] = gold_data2['Close'].rolling(window=10).mean()\n",
    "gold_data2['MA_50'] = gold_data2['Close'].rolling(window=50).mean()\n",
    "gold_data2['Volatility'] = gold_data2['Close'].rolling(window=10).std()\n",
    "gold_data2['Return'] = gold_data2['Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_gold_price():\n",
    "    ma_10 = 220.225999\n",
    "    ma_50 = 213.4290\n",
    "    volatility = 3.162183\n",
    "    return_pct =  -0.019945\n",
    "\n",
    "    input_data = pd.DataFrame([[ma_10, ma_50, volatility, return_pct]], columns=features)\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "    future_price = model.predict(input_data_scaled)\n",
    "    print(future_price)\n",
    "    return future_price[0]\n",
    "\n",
    "print(predict_future_gold_price())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_real_time_gold_price_alpha_vantage():\n",
    "    API_KEY = 'QYHRK01Q1ORWYPSJ'\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=GLD&interval=1min&apikey={API_KEY}'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "    if \"Time Series (1min)\" in data:\n",
    "        latest_time = list(data['Time Series (1min)'].keys())[0]\n",
    "        latest_data = data['Time Series (1min)'][latest_time]\n",
    "        latest_price = float(latest_data['4. close'])\n",
    "        return latest_price\n",
    "    else:\n",
    "        print(f\"Error fetching data: {data}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "gold_price = fetch_real_time_gold_price_alpha_vantage()\n",
    "if gold_price:\n",
    "    print(f\"Real-time gold price (via Alpha Vantage): ${gold_price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data2 = yf.download('GLD', start='2024-05-14', end='2024-05-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fetch historical gold prices (using GLD ETF as a proxy)\n",
    "gold_data = yf.download('GLD', start='2015-05-08', end='2024-05-24')\n",
    "print(gold_data.head())\n",
    "\n",
    "# Handle missing values\n",
    "gold_data = gold_data.dropna()\n",
    "\n",
    "# Create relevant features\n",
    "gold_data['MA_10'] = gold_data['Close'].rolling(window=10).mean()\n",
    "gold_data['MA_50'] = gold_data['Close'].rolling(window=50).mean()\n",
    "gold_data['Volatility'] = gold_data['Close'].rolling(window=10).std()\n",
    "gold_data['Return'] = gold_data['Close'].pct_change()\n",
    "\n",
    "# Drop rows with NaN values created by rolling window calculations\n",
    "gold_data = gold_data.dropna()\n",
    "print(gold_data.head())\n",
    "\n",
    "# Define features and target\n",
    "features = ['MA_10', 'MA_50', 'Volatility', 'Return']\n",
    "X = gold_data[features]\n",
    "y = gold_data['Close']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a regression model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "def fetch_real_time_gold_price_alpha_vantage():\n",
    "    # Replace with your actual Alpha Vantage API key\n",
    "    API_KEY = 'QYHRK01Q1ORWYPSJ'\n",
    "    symbol = 'GLD'  # GLD is an ETF that tracks the price of gold\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={symbol}&interval=1min&apikey={API_KEY}'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if \"Time Series (1min)\" in data:\n",
    "        latest_time = list(data['Time Series (1min)'].keys())[0]\n",
    "        latest_data = data['Time Series (1min)'][latest_time]\n",
    "        latest_price = float(latest_data['4. close'])\n",
    "        return latest_price\n",
    "    else:\n",
    "        print(f\"Error fetching data: {data}\")\n",
    "        return None\n",
    "\n",
    "def predict_future_gold_price():\n",
    "    # Fetch real-time gold data\n",
    "    gold_price = fetch_real_time_gold_price_alpha_vantage()\n",
    "    if gold_price is None:\n",
    "        return None\n",
    "\n",
    "    # Assume we have the recent values for MA_10, MA_50, Volatility, and Return\n",
    "    recent_data = gold_data.iloc[-1]\n",
    "    ma_10 = recent_data['MA_10']\n",
    "    ma_50 = recent_data['MA_50']\n",
    "    volatility = recent_data['Volatility']\n",
    "    return_pct = recent_data['Return']\n",
    "\n",
    "    # Prepare the input data for prediction\n",
    "    input_data = pd.DataFrame([[ma_10, ma_50, volatility, return_pct]], columns=features)\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "    # Predict future gold price\n",
    "    future_price = model.predict(input_data_scaled)\n",
    "    return future_price[0]\n",
    "\n",
    "# Example usage\n",
    "future_gold_price = predict_future_gold_price()\n",
    "if future_gold_price:\n",
    "    print(f\"Predicted future gold price: {future_gold_price}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ccxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the exchange (e.g., Binance)\n",
    "exchange = ccxt.binance()\n",
    "\n",
    "# Fetch historical data for Bitcoin\n",
    "symbol = 'BTC/USDT'\n",
    "timeframe = '1d'\n",
    "since = exchange.parse8601('2010-01-01T00:00:00Z')\n",
    "\n",
    "# Fetch the data\n",
    "ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since)\n",
    "data = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 500 records, total: 500\n",
      "Fetched 500 records, total: 1000\n",
      "Fetched 500 records, total: 1500\n",
      "Fetched 500 records, total: 2000\n",
      "Fetched 500 records, total: 2500\n",
      "Fetched 500 records, total: 3000\n",
      "Fetched 500 records, total: 3500\n",
      "Fetched 500 records, total: 4000\n",
      "Fetched 500 records, total: 4500\n",
      "Fetched 500 records, total: 5000\n",
      "Fetched 500 records, total: 5500\n",
      "Fetched 500 records, total: 6000\n",
      "Fetched 500 records, total: 6500\n",
      "Fetched 500 records, total: 7000\n",
      "Fetched 500 records, total: 7500\n",
      "Fetched 500 records, total: 8000\n",
      "Fetched 500 records, total: 8500\n",
      "Fetched 500 records, total: 9000\n",
      "Fetched 500 records, total: 9500\n",
      "Fetched 500 records, total: 10000\n",
      "Fetched 500 records, total: 10500\n",
      "Fetched 500 records, total: 11000\n",
      "Fetched 500 records, total: 11500\n",
      "Fetched 500 records, total: 12000\n",
      "Fetched 500 records, total: 12500\n",
      "Fetched 500 records, total: 13000\n",
      "Fetched 500 records, total: 13500\n",
      "Fetched 500 records, total: 14000\n",
      "Fetched 500 records, total: 14500\n",
      "Fetched 500 records, total: 15000\n",
      "Fetched 500 records, total: 15500\n",
      "Fetched 500 records, total: 16000\n",
      "Fetched 500 records, total: 16500\n",
      "Fetched 500 records, total: 17000\n",
      "Fetched 500 records, total: 17500\n",
      "Fetched 500 records, total: 18000\n",
      "Fetched 500 records, total: 18500\n",
      "Fetched 500 records, total: 19000\n",
      "Fetched 500 records, total: 19500\n",
      "Fetched 500 records, total: 20000\n",
      "Fetched 500 records, total: 20500\n",
      "Fetched 500 records, total: 21000\n",
      "Fetched 500 records, total: 21500\n",
      "Fetched 500 records, total: 22000\n",
      "Fetched 500 records, total: 22500\n",
      "Fetched 500 records, total: 23000\n",
      "Fetched 500 records, total: 23500\n",
      "Fetched 500 records, total: 24000\n",
      "Fetched 500 records, total: 24500\n",
      "Fetched 500 records, total: 25000\n",
      "Fetched 500 records, total: 25500\n",
      "Fetched 500 records, total: 26000\n",
      "Fetched 500 records, total: 26500\n",
      "Fetched 500 records, total: 27000\n",
      "Fetched 500 records, total: 27500\n",
      "Fetched 500 records, total: 28000\n",
      "Fetched 500 records, total: 28500\n",
      "Fetched 500 records, total: 29000\n",
      "Fetched 500 records, total: 29500\n",
      "Fetched 500 records, total: 30000\n",
      "Fetched 500 records, total: 30500\n",
      "Fetched 500 records, total: 31000\n",
      "Fetched 500 records, total: 31500\n",
      "Fetched 500 records, total: 32000\n",
      "Fetched 500 records, total: 32500\n",
      "Fetched 500 records, total: 33000\n",
      "Fetched 500 records, total: 33500\n",
      "Fetched 500 records, total: 34000\n",
      "Fetched 500 records, total: 34500\n",
      "Fetched 500 records, total: 35000\n",
      "Fetched 500 records, total: 35500\n",
      "Fetched 500 records, total: 36000\n",
      "Fetched 500 records, total: 36500\n",
      "Fetched 500 records, total: 37000\n",
      "Fetched 500 records, total: 37500\n",
      "Fetched 500 records, total: 38000\n",
      "Fetched 500 records, total: 38500\n",
      "Fetched 500 records, total: 39000\n",
      "Fetched 500 records, total: 39500\n",
      "Fetched 500 records, total: 40000\n",
      "Fetched 500 records, total: 40500\n",
      "Fetched 500 records, total: 41000\n",
      "Fetched 500 records, total: 41500\n",
      "Fetched 500 records, total: 42000\n",
      "Fetched 500 records, total: 42500\n",
      "Fetched 500 records, total: 43000\n",
      "Fetched 500 records, total: 43500\n",
      "Fetched 500 records, total: 44000\n",
      "Fetched 500 records, total: 44500\n",
      "Fetched 500 records, total: 45000\n",
      "Fetched 500 records, total: 45500\n",
      "Fetched 500 records, total: 46000\n",
      "Fetched 500 records, total: 46500\n",
      "Fetched 500 records, total: 47000\n",
      "Fetched 500 records, total: 47500\n",
      "Fetched 500 records, total: 48000\n",
      "Fetched 500 records, total: 48500\n",
      "Fetched 500 records, total: 49000\n",
      "Fetched 500 records, total: 49500\n",
      "Fetched 500 records, total: 50000\n",
      "Fetched 500 records, total: 50500\n",
      "Fetched 500 records, total: 51000\n",
      "Fetched 500 records, total: 51500\n",
      "Fetched 500 records, total: 52000\n",
      "Fetched 500 records, total: 52500\n",
      "Fetched 500 records, total: 53000\n",
      "Fetched 500 records, total: 53500\n",
      "Fetched 500 records, total: 54000\n",
      "Fetched 500 records, total: 54500\n",
      "Fetched 500 records, total: 55000\n",
      "Fetched 500 records, total: 55500\n",
      "Fetched 500 records, total: 56000\n",
      "Fetched 500 records, total: 56500\n",
      "Fetched 154 records, total: 56654\n",
      "            timestamp     open     high      low    close     volume\n",
      "0 2017-08-17 04:00:00  4261.48  4313.62  4261.32  4308.83  47.181009\n",
      "1 2017-08-17 05:00:00  4308.83  4328.69  4291.37  4315.32  23.234916\n",
      "2 2017-08-17 06:00:00  4330.29  4345.45  4309.37  4324.35   7.229691\n",
      "3 2017-08-17 07:00:00  4316.62  4349.99  4287.41  4349.99   4.443249\n",
      "4 2017-08-17 08:00:00  4333.32  4377.85  4333.32  4360.69   0.972807\n",
      "                timestamp      open      high       low     close     volume\n",
      "56649 2024-05-26 04:00:00  69073.62  69073.62  68936.21  68974.00  270.48984\n",
      "56650 2024-05-26 05:00:00  68973.99  69139.60  68928.22  69139.60  219.54140\n",
      "56651 2024-05-26 06:00:00  69139.59  69184.00  69052.00  69105.63  273.93522\n",
      "56652 2024-05-26 07:00:00  69105.64  69435.36  69101.63  69340.15  620.99560\n",
      "56653 2024-05-26 08:00:00  69340.16  69562.23  69260.00  69284.01  534.10881\n"
     ]
    }
   ],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize the exchange (e.g., Binance)\n",
    "exchange = ccxt.binance()\n",
    "\n",
    "# Fetch historical data for Bitcoin\n",
    "symbol = 'BTC/USDT'\n",
    "timeframe = '1h'\n",
    "since = exchange.parse8601('2010-01-01T00:00:00Z')\n",
    "limit = 100\n",
    "all_ohlcv = []\n",
    "\n",
    "while since < exchange.milliseconds():\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since)\n",
    "    if not ohlcv:\n",
    "        break\n",
    "    since = ohlcv[-1][0] + 24 * 60 * 60 * 1000  # Move to the next day in milliseconds\n",
    "    all_ohlcv.extend(ohlcv)\n",
    "    print(f\"Fetched {len(ohlcv)} records, total: {len(all_ohlcv)}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "data = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "print(data.head())\n",
    "print(data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp     open     high      low    close     volume  \\\n",
      "49 2017-08-19 05:00:00  4123.95  4123.95  4027.83  4077.00  12.514194   \n",
      "50 2017-08-19 06:00:00  4077.00  4082.00  3986.87  3986.87  51.455431   \n",
      "51 2017-08-19 07:00:00  3969.12  4033.47  3933.21  4033.47  31.429222   \n",
      "52 2017-08-19 08:00:00  4033.47  4064.84  3964.08  3999.00  18.006405   \n",
      "53 2017-08-19 09:00:00  3999.00  4082.25  3999.00  4068.20   5.184223   \n",
      "\n",
      "       MA_10      MA_50  Volatility    Return  \n",
      "49  4097.114  4271.1166   61.860902  0.002148  \n",
      "50  4093.690  4264.6774   67.248159 -0.022107  \n",
      "51  4099.468  4259.0404   57.801798  0.011688  \n",
      "52  4087.993  4252.5334   65.525667 -0.008546  \n",
      "53  4083.976  4246.8976   65.368779  0.017304  \n"
     ]
    }
   ],
   "source": [
    "# Create relevant features\n",
    "data['MA_10'] = data['close'].rolling(window=10).mean()\n",
    "data['MA_50'] = data['close'].rolling(window=50).mean()\n",
    "data['Volatility'] = data['close'].rolling(window=10).std()\n",
    "data['Return'] = data['close'].pct_change()\n",
    "\n",
    "# Drop rows with NaN values created by rolling window calculations\n",
    "data = data.dropna()\n",
    "print(data.head())\n",
    "\n",
    "# Define features and target\n",
    "features = ['MA_10', 'MA_50', 'Volatility', 'Return']\n",
    "X = data[features]\n",
    "y = data['close']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46709752, -0.46319961, -0.5089183 ,  0.05664562],\n",
       "       [-0.98457457, -0.97965955, -0.88710268,  0.13034093],\n",
       "       [-0.84055425, -0.84612084, -0.95643357,  0.07324324],\n",
       "       ...,\n",
       "       [-0.98376591, -0.98587871, -0.95971085,  0.01967343],\n",
       "       [-0.76129862, -0.73783976, -0.93367652,  0.05012297],\n",
       "       [ 0.8137817 ,  0.81216526, -0.70924394,  0.05174475]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 56605 entries, 49 to 56653\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   timestamp   56605 non-null  datetime64[ns]\n",
      " 1   open        56605 non-null  float64       \n",
      " 2   high        56605 non-null  float64       \n",
      " 3   low         56605 non-null  float64       \n",
      " 4   close       56605 non-null  float64       \n",
      " 5   volume      56605 non-null  float64       \n",
      " 6   MA_10       56605 non-null  float64       \n",
      " 7   MA_50       56605 non-null  float64       \n",
      " 8   Volatility  56605 non-null  float64       \n",
      " 9   Return      56605 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(9)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>MA_10</th>\n",
       "      <th>MA_50</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56649</th>\n",
       "      <td>2024-05-26 04:00:00</td>\n",
       "      <td>69073.62</td>\n",
       "      <td>69073.62</td>\n",
       "      <td>68936.21</td>\n",
       "      <td>68974.00</td>\n",
       "      <td>270.48984</td>\n",
       "      <td>69108.298</td>\n",
       "      <td>68558.3758</td>\n",
       "      <td>106.950818</td>\n",
       "      <td>-0.001442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56650</th>\n",
       "      <td>2024-05-26 05:00:00</td>\n",
       "      <td>68973.99</td>\n",
       "      <td>69139.60</td>\n",
       "      <td>68928.22</td>\n",
       "      <td>69139.60</td>\n",
       "      <td>219.54140</td>\n",
       "      <td>69106.726</td>\n",
       "      <td>68583.3312</td>\n",
       "      <td>106.296406</td>\n",
       "      <td>0.002401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56651</th>\n",
       "      <td>2024-05-26 06:00:00</td>\n",
       "      <td>69139.59</td>\n",
       "      <td>69184.00</td>\n",
       "      <td>69052.00</td>\n",
       "      <td>69105.63</td>\n",
       "      <td>273.93522</td>\n",
       "      <td>69107.288</td>\n",
       "      <td>68611.2792</td>\n",
       "      <td>106.271806</td>\n",
       "      <td>-0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56652</th>\n",
       "      <td>2024-05-26 07:00:00</td>\n",
       "      <td>69105.64</td>\n",
       "      <td>69435.36</td>\n",
       "      <td>69101.63</td>\n",
       "      <td>69340.15</td>\n",
       "      <td>620.99560</td>\n",
       "      <td>69127.402</td>\n",
       "      <td>68652.0824</td>\n",
       "      <td>129.450105</td>\n",
       "      <td>0.003394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56653</th>\n",
       "      <td>2024-05-26 08:00:00</td>\n",
       "      <td>69340.16</td>\n",
       "      <td>69562.23</td>\n",
       "      <td>69260.00</td>\n",
       "      <td>69284.01</td>\n",
       "      <td>534.10881</td>\n",
       "      <td>69142.903</td>\n",
       "      <td>68700.0224</td>\n",
       "      <td>138.618849</td>\n",
       "      <td>-0.000810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp      open      high       low     close     volume  \\\n",
       "56649 2024-05-26 04:00:00  69073.62  69073.62  68936.21  68974.00  270.48984   \n",
       "56650 2024-05-26 05:00:00  68973.99  69139.60  68928.22  69139.60  219.54140   \n",
       "56651 2024-05-26 06:00:00  69139.59  69184.00  69052.00  69105.63  273.93522   \n",
       "56652 2024-05-26 07:00:00  69105.64  69435.36  69101.63  69340.15  620.99560   \n",
       "56653 2024-05-26 08:00:00  69340.16  69562.23  69260.00  69284.01  534.10881   \n",
       "\n",
       "           MA_10       MA_50  Volatility    Return  \n",
       "56649  69108.298  68558.3758  106.950818 -0.001442  \n",
       "56650  69106.726  68583.3312  106.296406  0.002401  \n",
       "56651  69107.288  68611.2792  106.271806 -0.000491  \n",
       "56652  69127.402  68652.0824  129.450105  0.003394  \n",
       "56653  69142.903  68700.0224  138.618849 -0.000810  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 91549.36927983354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Train a regression model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Save the model to a .pkl file\n",
    "import pickle\n",
    "with open('crypto_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Save the scaler to a .pkl file\n",
    "with open('crypto_scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "def get_stock_advice(url):\n",
    "    # Send a GET request to the website\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the section containing the news articles\n",
    "        middle_section = soup.find('div', {'class': 'middle_section'})\n",
    "        \n",
    "        # Prepare data for JSON\n",
    "        data = []\n",
    "        \n",
    "        if middle_section:\n",
    "            # Extract individual news items from 'news_list'\n",
    "            news_list = middle_section.find('ul', {'class': 'news_list'})\n",
    "            if news_list:\n",
    "                articles = news_list.find_all('li')\n",
    "                for article in articles:\n",
    "                    stock_info = article.find('div', {'class': 'rb_gd14'})\n",
    "                    stock_name_link = stock_info.find('a')\n",
    "                    stock_name = stock_name_link.get_text(strip=True)\n",
    "                    stock_price = stock_info.find_all('strong')[1].get_text(strip=True).replace(',', '')\n",
    "                    \n",
    "                    try:\n",
    "                        stock_price_float = float(stock_price)\n",
    "                    except ValueError:\n",
    "                        stock_price_float = 0.0\n",
    "                    \n",
    "                    article_link = article.find('div', {'class': 'MT5'}).find('a')\n",
    "                    recommendation = article_link.get_text(strip=True)\n",
    "                    \n",
    "                    # Trim recommendation up to the first colon and parse details\n",
    "                    recommendation_parts = recommendation.split(':')\n",
    "                    if len(recommendation_parts) > 1:\n",
    "                        recommendation_trimmed = recommendation_parts[0].split(';')[0].strip()\n",
    "                        source = recommendation_parts[-1].strip()\n",
    "                    else:\n",
    "                        recommendation_trimmed = recommendation\n",
    "                        source = ''\n",
    "                    \n",
    "                    # Extract target price\n",
    "                    match = re.search(r'target of Rs (\\d+[:,]?\\d+)', recommendation)\n",
    "                    if match:\n",
    "                        target_value = match.group(1).replace(',', '')\n",
    "                        try:\n",
    "                            target_value_float = float(target_value)\n",
    "                        except ValueError:\n",
    "                            target_value_float = 0.0\n",
    "                    else:\n",
    "                        target_value = ''\n",
    "                        target_value_float = 0.0\n",
    "                    \n",
    "                    # Calculate revenue\n",
    "                    revenue = target_value_float - stock_price_float\n",
    "                    \n",
    "                    # Calculate profit percent\n",
    "                    if stock_price_float != 0:\n",
    "                        profit_percent = (revenue / stock_price_float) * 100\n",
    "                    else:\n",
    "                        profit_percent = 0.0\n",
    "                    \n",
    "                    data.append({\n",
    "                        'Stock Name': stock_name,\n",
    "                        'Price': f'Rs {stock_price}',\n",
    "                        'Recommendation': recommendation_trimmed,\n",
    "                        'Target Price': target_value,\n",
    "                        'Source': source,\n",
    "                        'Revenue': f'Rs {revenue:.2f}',\n",
    "                        'Profit Percent': f'{profit_percent:.2f}%'\n",
    "                    })\n",
    "            else:\n",
    "                return json.dumps({'error': 'No news list found on the page.'})\n",
    "        else:\n",
    "            return json.dumps({'error': 'No middle section found on the page.'})\n",
    "    else:\n",
    "        return json.dumps({'error': 'Failed to retrieve the webpage.'})\n",
    "    \n",
    "    # Sort data by profit percent in descending order and select top 3\n",
    "    top_3_stocks = sorted(data, key=lambda x: float(x['Profit Percent'].replace('%', '')), reverse=True)[:3]\n",
    "    \n",
    "    return json.dumps(top_3_stocks, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_top_cryptos(url1):\n",
    "    # Send a GET request to the website\n",
    "    response = requests.get(url1)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the table containing the cryptocurrency data\n",
    "        table = soup.find('table', {'class': 'tableWrapper_web_tbl_indices__qR1nw'})\n",
    "\n",
    "        if table:\n",
    "            # Extract rows from the table\n",
    "            rows = table.find_all('tr')[1:]  # Exclude header row\n",
    "            top_3_rows = rows[:3]  # Select only the top 3 rows\n",
    "\n",
    "            data = []\n",
    "            for row in top_3_rows:\n",
    "                columns = row.find_all('td')\n",
    "                name = columns[0].get_text(strip=True)\n",
    "                price = columns[1].get_text(strip=True).replace(',', '')\n",
    "                chg_percent = columns[3].get_text(strip=True)\n",
    "                high_52_week = columns[6].get_text(strip=True).replace(',', '')\n",
    "                low_52_week = columns[7].get_text(strip=True).replace(',', '')\n",
    "                technical_review = columns[8].get_text(strip=True)  \n",
    "\n",
    "                data.append({\n",
    "                    'Name': name,\n",
    "                    'Price': f'Rs. {price}',\n",
    "                    'Change Percent': chg_percent,\n",
    "                    '52 Week High': f'Rs. {high_52_week}',\n",
    "                    '52 Week Low': f'Rs. {low_52_week}',\n",
    "                    'Technical Review': technical_review\n",
    "                })\n",
    "\n",
    "            return json.dumps(data, indent=4)\n",
    "        else:\n",
    "            return json.dumps({'error': 'No table found on the page.'})\n",
    "    else:\n",
    "        return json.dumps({'error': 'Failed to retrieve the webpage.'})\n",
    "\n",
    "\n",
    "# URL of the website\n",
    "url = 'https://m.moneycontrol.com/markets/stock-advice/'\n",
    "top_3_stocks_json = get_stock_advice(url)\n",
    "print(top_3_stocks_json)\n",
    "\n",
    "url1 = 'https://www.moneycontrol.com/crypto-market/market-movers/top-cryptos/inr'\n",
    "top_3_cryptos_json = get_top_cryptos(url1)\n",
    "print(top_3_cryptos_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
